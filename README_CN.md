# HydraLLM

[English](README.md) | ç®€ä½“ä¸­æ–‡ | [æ—¥æœ¬èª](README_JP.md)

```mermaid
flowchart LR
  C["é‡è¯•å½“å‰æ¨¡å‹"] -->|"å¤±è´¥"| D["å›é€€åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"];
  D -->|"ä¸‹ä¸€ä¸ª"| C;
  C -->|"æˆåŠŸ"| E["âœ… è¿”å›å“åº”"];
  D -->|"è€—å°½"| F["âŒ è¿”å›é”™è¯¯"];

  classDef muted fill:#F8FAFC,stroke:#CBD5E1,color:#64748B,stroke-width:1px;
  classDef flow fill:#FFF7ED,stroke:#EA580C,color:#7C2D12,stroke-width:3px;
  classDef flow2 fill:#FEF3C7,stroke:#D97706,color:#78350F,stroke-width:3px;
  classDef ok fill:#DCFCE7,stroke:#16A34A,color:#14532D,stroke-width:1.5px;
  classDef bad fill:#FEE2E2,stroke:#DC2626,color:#7F1D1D,stroke-width:1.5px;
  class C flow;
  class D flow2;
  class E ok;
  class F bad;
```

HydraLLM æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ LLM API ä»£ç†ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¯•ä¸æ¨¡å‹å›é€€ï¼Œå¯åœ¨ OpenAI å…¼å®¹ã€Anthropic å…¼å®¹å’Œ AWS Bedrock æä¾›å•†ä¹‹é—´å·¥ä½œã€‚

å½“è¯·æ±‚å¤±è´¥æ—¶ï¼ŒHydraLLM ä¼šå…ˆé‡è¯•å½“å‰æ¨¡å‹ï¼Œå†æŒ‰é…ç½®é¡ºåºå›é€€åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹ï¼Œç›´åˆ°æˆåŠŸæˆ–å…¨éƒ¨è€—å°½ã€‚

> [!TIP]
> å®Œæ•´é…ç½®å­—æ®µä¸ç¤ºä¾‹è¯·æŸ¥çœ‹ [CONFIGURATION.md](CONFIGURATION.md)ã€‚

## âœ¨ ä¸ºä»€ä¹ˆé€‰æ‹© HydraLLM

- ä¸ºç¼–ç ä¸ Agent åœºæ™¯æä¾›è‡ªåŠ¨é‡è¯• + å›é€€ã€‚
- å¤šæä¾›å•†æ”¯æŒï¼šOpenAI å…¼å®¹ã€Anthropic å…¼å®¹ã€AWS Bedrockã€‚
- æä¾›ç¨³å®šçš„æœ¬åœ°ç»Ÿä¸€å…¥å£ï¼Œå³ä½¿æ¨¡å‹é“¾å˜åŒ–ä¹Ÿèƒ½å¹³æ»‘æ¥å…¥ã€‚

## ğŸ“¦ å®‰è£…

### Homebrewï¼ˆmacOS / Linuxï¼‰

```bash
brew install fang2hou/tap/hydrallm
```

### é€šè¿‡ Go å®‰è£…ï¼ˆå…¨å¹³å°ï¼‰

```bash
go install github.com/fang2hou/hydrallm@latest
```

### ä¸‹è½½å·²ç¼–è¯‘äºŒè¿›åˆ¶ï¼ˆå…¨å¹³å°ï¼‰

ä» [GitHub Releases](https://github.com/fang2hou/hydrallm/releases) ä¸‹è½½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆGLM Coding Planï¼‰

æœ¬é¡¹ç›®æä¾›çš„ GLM showcase åœ¨åŒä¸€ä»½é…ç½®ä¸­æä¾›ä¸¤ä¸ªç›‘å¬ç«¯å£ï¼š

- OpenAI å…¼å®¹ APIï¼š`http://127.0.0.1:8101`
- Anthropic å…¼å®¹ APIï¼š`http://127.0.0.1:8102`

### 1) å‡†å¤‡é…ç½®

**macOS / Linuxï¼š**

```bash
mkdir -p ~/.config/hydrallm
curl -o ~/.config/hydrallm/config.toml \
  https://raw.githubusercontent.com/fang2hou/hydrallm/main/showcases/glm-coding-plan.toml
```

**Windowsï¼ˆPowerShellï¼‰ï¼š**

```powershell
New-Item -ItemType Directory -Force -Path "$env:USERPROFILE\.config\hydrallm"
Invoke-WebRequest -Uri "https://raw.githubusercontent.com/fang2hou/hydrallm/main/showcases/glm-coding-plan.toml" -OutFile "$env:USERPROFILE\.config\hydrallm\config.toml"
```

### 2) è®¾ç½® API Key

**macOS / Linuxï¼š**

```bash
export ZAI_API_KEY="your-api-key"
```

**Windowsï¼ˆPowerShellï¼‰ï¼š**

```powershell
$env:ZAI_API_KEY = "your-api-key"
```

### 3) å¯åŠ¨ä»£ç†

```bash
hydrallm
```

### 4) éªŒè¯ç›‘å¬ç«¯å£

<details>
<summary><b>OpenAI å…¼å®¹ç›‘å¬ç«¯å£ï¼ˆ8101ï¼‰</b></summary>

```bash
curl http://127.0.0.1:8101/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "placeholder",
    "messages": [{"role": "user", "content": "Say hello"}]
  }'
```

</details>

<details>
<summary><b>Anthropic å…¼å®¹ç›‘å¬ç«¯å£ï¼ˆ8102ï¼‰</b></summary>

```bash
curl http://127.0.0.1:8102/v1/messages \
  -H "Content-Type: application/json" \
  -d '{
    "model": "placeholder",
    "max_tokens": 64,
    "messages": [{"role": "user", "content": "Say hello"}]
  }'
```

</details>

> [!NOTE]
> HydraLLM ä¼šæŠŠè¯·æ±‚ä¸­çš„ `model` è¦†ç›–ä¸ºè¯¥ç›‘å¬ç«¯å£é…ç½®çš„æ¨¡å‹é“¾ã€‚

## ğŸ” æœåŠ¡æ¨¡å¼ï¼ˆå¼€æœºè‡ªå¯ï¼‰

å¯ä½¿ç”¨ Homebrew services å®ç°è‡ªåŠ¨å¯åŠ¨ã€‚

> [!NOTE]
> ä½¿ç”¨ `brew services` æ—¶ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜¾å¼è®¾ç½® `api_key`ï¼Œä¸è¦ä¾èµ– shell ç¯å¢ƒå˜é‡ã€‚

```bash
brew services start hydrallm
brew services info hydrallm
brew services restart hydrallm
brew services stop hydrallm
```

- macOSï¼š`launchd`ï¼ˆç™»å½•åè‡ªåŠ¨å¯åŠ¨ï¼‰
- Linuxï¼š`systemd`

## ğŸ› ï¸ CLI å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|---|---|
| `hydrallm` | å¯åŠ¨æœåŠ¡ |
| `hydrallm serve` | å¯åŠ¨ä»£ç† |
| `hydrallm edit` | ç”¨ `$EDITOR` æ‰“å¼€é…ç½® |
| `hydrallm version` | è¾“å‡ºç‰ˆæœ¬ä¿¡æ¯ |
| `hydrallm --help` | æŸ¥çœ‹å¸®åŠ© |

å…¨å±€å‚æ•°ï¼š`--config /path/to/config.toml`ã€`--log-level info`

## ğŸ§¯ æ•…éšœæ’æŸ¥

å¿«é€Ÿè¯Šæ–­ï¼š

```bash
hydrallm --config /path/to/config.toml --log-level debug
brew services list | grep hydrallm
```

<details>
<summary><b>é…ç½®æ ¡éªŒå¤±è´¥ï¼šè‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ªæ¨¡å‹ï¼ˆconfig validation failed: at least one model must be configuredï¼‰</b></summary>

åœ¨ `[models.<id>]` ä¸‹è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹ã€‚

</details>

<details>
<summary><b>æ¨¡å‹ "..."ï¼šæœªæ‰¾åˆ°æä¾›å•† "..."ï¼ˆmodel "...": provider "..." not foundï¼‰</b></summary>

ç¡®ä¿æ¯ä¸ªæ¨¡å‹çš„ `provider` éƒ½èƒ½åœ¨ `[providers.<name>]` ä¸­æ‰¾åˆ°å¯¹åº”é¡¹ã€‚

</details>

<details>
<summary><b>ç›‘å¬å™¨ "..."ï¼šä¸å…è®¸æ··ç”¨æ¨¡å‹ç±»å‹ï¼ˆlistener "...": mixed model types are not allowedï¼‰</b></summary>

åŒä¸€ä¸ª listener é‡Œæ‰€æœ‰æ¨¡å‹å¿…é¡»æ˜¯åŒä¸€ API ç±»å‹ï¼ˆ`openai`ã€`anthropic` æˆ– `bedrock`ï¼‰ã€‚
è¯·æŠŠæ··åˆç±»å‹æ‹†åˆ†åˆ°å¤šä¸ª listenerã€‚

</details>

<details>
<summary><b>è¯·æ±‚è¿”å›ä¸Šæ¸¸ 4xx/5xxï¼ˆRequests return upstream 4xx/5xxï¼‰</b></summary>

å¯ä¸´æ—¶è®¾ç½® `log.include_error_body = true`ï¼ŒæŸ¥çœ‹ä¸Šæ¸¸é”™è¯¯è¯¦æƒ…ã€‚

</details>

## ğŸ“„ è®¸å¯è¯

MIT
